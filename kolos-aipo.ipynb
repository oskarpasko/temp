{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a73c77c",
   "metadata": {},
   "source": [
    "ZADANIE 1. (2 pkt): Gradient i podstawowa manipulacja obrazem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c546e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in c:\\users\\oskar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.26.0)\n",
      "Requirement already satisfied: numpy>=1.24 in c:\\users\\oskar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image) (2.2.1)\n",
      "Requirement already satisfied: scipy>=1.11.4 in c:\\users\\oskar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image) (1.16.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\oskar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image) (3.5)\n",
      "Requirement already satisfied: pillow>=10.1 in c:\\users\\oskar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image) (11.2.1)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in c:\\users\\oskar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image) (2.37.2)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\oskar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image) (2026.1.28)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\oskar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image) (25.0)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\oskar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-image) (0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 26.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE między scipy a OpenCV: 0.13440964\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Zastosuj rozmycie Gaussa na obrazie (w skali szarości) przy użyciu:\n",
    "\n",
    "#    scipy.ndimage.gaussian_filter\n",
    "#    cv2.GaussianBlur\n",
    "\n",
    "# Samodzielnie napisz funkcję do obliczania błędu średniokwadratowego (MSE) za pomocą numpy.\n",
    "# Porównaj wyniki obu metod, obliczając MSE między obrazami rozmytymi. Jeśli występują różnice pomiędzy wynikami obu metod\n",
    "# skomentuj, z czego one (Twoim zdaniem) wynikają.\n",
    "%pip install scikit-image\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import cv2\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Wczytanie obrazu w kolorze i konwersja na skalę szarości\n",
    "img_color = io.imread('https://i.postimg.cc/mksNZfXc/BoQS.png')\n",
    "img_gray = cv2.cvtColor(img_color, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# Rozmycie Gaussa za pomocą scipy.ndimage.gaussian_filter\n",
    "def gaussian_blur_scipy(img, sigma):\n",
    "    return gaussian_filter(img, sigma=sigma)\n",
    "\n",
    "# Rozmycie Gaussa za pomocą cv2.GaussianBlur\n",
    "def gaussian_blur_opencv(img, sigma):\n",
    "    return cv2.GaussianBlur(img, (0, 0), sigmaX=sigma, sigmaY=sigma)\n",
    "\n",
    "# Obliczenie MSE\n",
    "def mean_squared_error(img1, img2):\n",
    "    img1 = img1.astype(np.float32)\n",
    "    img2 = img2.astype(np.float32)\n",
    "    return np.mean((img1 - img2) ** 2)\n",
    "\n",
    "# Zastosuj rozmycie i oblicz MSE\n",
    "sigma = 2\n",
    "blur_scipy = gaussian_blur_scipy(img_gray, sigma)\n",
    "blur_opencv = gaussian_blur_opencv(img_gray, sigma)\n",
    "mse = mean_squared_error(blur_scipy, blur_opencv)\n",
    "\n",
    "##### Wypisz wynik i skomentuj\n",
    "\n",
    "print(\"MSE między scipy a OpenCV:\", mse)\n",
    "\n",
    "# Niewielkie różnice pomiędzy wynikami rozmycia Gaussa w \n",
    "# scipy.ndimage.gaussian_filter oraz cv2.GaussianBlur wynikają z:\n",
    "# - innego sposobu wyznaczania rozmiaru maski Gaussa,\n",
    "# - różnic w implementacji filtracji brzegów obrazu,\n",
    "# - możliwych różnic numerycznych (precyzja obliczeń).\n",
    "# Obie metody realizują filtr Gaussa, jednak szczegóły implementacyjne powodują drobne różnice pikselowe, co skutkuje niezerową wartością MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a2e49a",
   "metadata": {},
   "source": [
    "KOD INICJALIZUJĄCY, TYLKO URUCHOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef9d777c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in c:\\users\\oskar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 26.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 3, 32, 32])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 3, 32, 32])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "%pip install torchsummary\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.transforms import functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "training_data = datasets.CIFAR10(root=\"data\",train=True,download=True,transform=ToTensor(),)\n",
    "test_data = datasets.CIFAR10(root=\"data\",train=False, download=True, transform=ToTensor(),)\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break\n",
    "for X, y in train_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break\n",
    "\n",
    "#### KONIEC KODU INICJALIZUJACEGO BIBLIOTEKI I DANE ####\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e3ebc2",
   "metadata": {},
   "source": [
    "ZADANIE 2. (2 pkt): Definicja sieci fully-connected w pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2c20562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Flatten-1                 [-1, 3072]               0\n",
      "            Linear-2                  [-1, 256]         786,688\n",
      "              ReLU-3                  [-1, 256]               0\n",
      "            Linear-4                  [-1, 256]          65,792\n",
      "              ReLU-5                  [-1, 256]               0\n",
      "            Linear-6                  [-1, 256]          65,792\n",
      "              ReLU-7                  [-1, 256]               0\n",
      "            Linear-8                   [-1, 10]           2,570\n",
      "================================================================\n",
      "Total params: 920,842\n",
      "Trainable params: 920,842\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.04\n",
      "Params size (MB): 3.51\n",
      "Estimated Total Size (MB): 3.56\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Uzupełnij definicję klasy NeuralNetwork tak, aby uzyskać sieć fully-connected z:\n",
    "#    warstwą wejściową: 3072 wejścia, 256 wyjść,\n",
    "#    dwiema warstwami ukrytymi: każda z 256 wejść i 256 wyjść,\n",
    "#    warstwą wyjściową: 256 wejść, 10 wyjść,\n",
    "#    funkcjami aktywacji ReLU między wszystkimi warstwami.\n",
    "\n",
    "# Zdefiniuj ręcznie funkcję forward, aby obsługiwała:\n",
    "\n",
    "#    spłaszczenie danych wejściowych,\n",
    "#    przejście przez wszystkie warstwy sieci.\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.fc1 = nn.Linear(3 * 32 * 32, 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc3 = nn.Linear(256, 256)\n",
    "        self.fc4 = nn.Linear(256, 10)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "summary(model, (3, 32, 32))\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4997dda5",
   "metadata": {},
   "source": [
    "ZADANIE 3. (1 pkt): Uczenie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a2ba1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# W poniższej funkcji służącej do uczenia modelu jest błąd, który powoduje, że\n",
    "# model się nie uczy, a dokładność klasyfikacji nie rośnie (możesz to zaobserwować uruchamiając\n",
    "# komórki niżej, z definicją funkcji test i pętlą uczenia)\n",
    "\n",
    "# popraw funkcję train tak, aby model uczył się poprawnie i opisz w komentarzu na czym polegał błąd.\n",
    "\n",
    "# def train(dataloader, model, loss_fn, optimizer):\n",
    "#     size = len(dataloader.dataset)\n",
    "#     model.train()\n",
    "#     for batch, (X, y) in enumerate(dataloader):\n",
    "#         X, y = X.to(device), y.to(device)\n",
    "#         pred = model(X)\n",
    "#         loss = loss_fn(pred, y)\n",
    "#         loss.backward()\n",
    "#         optimizer.zero_grad()\n",
    "#         optimizer.step()\n",
    "#         if batch % 100 == 0:\n",
    "#             loss, current = loss.item(), batch * len(X)\n",
    "#             print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "# Błąd polegał na wywoływaniu optimizer.zero_grad() po loss.backward(). \n",
    "# Powodowało to kumulację gradientów pomiędzy batchami, \n",
    "# co uniemożliwiało poprawne uczenie modelu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59b30cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91936e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.197964  [    0/50000]\n",
      "loss: 2.182566  [ 6400/50000]\n",
      "loss: 2.100182  [12800/50000]\n",
      "loss: 2.194709  [19200/50000]\n",
      "loss: 2.142306  [25600/50000]\n",
      "loss: 2.135033  [32000/50000]\n",
      "loss: 2.206599  [38400/50000]\n",
      "loss: 2.151149  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 23.9%, Avg loss: 2.152954 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.197964  [    0/50000]\n",
      "loss: 2.182566  [ 6400/50000]\n",
      "loss: 2.100182  [12800/50000]\n",
      "loss: 2.194709  [19200/50000]\n",
      "loss: 2.142306  [25600/50000]\n",
      "loss: 2.135033  [32000/50000]\n",
      "loss: 2.206599  [38400/50000]\n",
      "loss: 2.151149  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 23.9%, Avg loss: 2.152954 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.197964  [    0/50000]\n",
      "loss: 2.182566  [ 6400/50000]\n",
      "loss: 2.100182  [12800/50000]\n",
      "loss: 2.194709  [19200/50000]\n",
      "loss: 2.142306  [25600/50000]\n",
      "loss: 2.135033  [32000/50000]\n",
      "loss: 2.206599  [38400/50000]\n",
      "loss: 2.151149  [44800/50000]\n",
      "Test Error: \n",
      " Accuracy: 23.9%, Avg loss: 2.152954 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.197964  [    0/50000]\n",
      "loss: 2.182566  [ 6400/50000]\n",
      "loss: 2.100182  [12800/50000]\n",
      "loss: 2.194709  [19200/50000]\n",
      "loss: 2.142306  [25600/50000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m-------------------------------\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     test(test_dataloader, model, loss_fn)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDone!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(dataloader, model, loss_fn, optimizer)\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch, (X, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[32m     11\u001b[39m     X, y = X.to(device), y.to(device)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     pred = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     loss = loss_fn(pred, y)\n\u001b[32m     14\u001b[39m     loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mNeuralNetwork.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     28\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.flatten(x)\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.relu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     30\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.relu(\u001b[38;5;28mself\u001b[39m.fc2(x))\n\u001b[32m     31\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.relu(\u001b[38;5;28mself\u001b[39m.fc3(x))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8da7c7c",
   "metadata": {},
   "source": [
    "ZADANIE 4. (1 pkt): Augmentacja danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b54498d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 3, 32, 32])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 3, 32, 32])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Zmodyfikuj kod wczytujący dany tak, aby wprowadzić augmentację danych do zbioru treningowego.\n",
    "# Augmentacja powinna zawierać następujące operacje:\n",
    "\n",
    "#    Losowy obrót obrazu w zakresie od (−15∘, 15∘).\n",
    "#    Losowe odbicie poziome obrazu z prawdopodobieństwem 0.5\n",
    "#    Losowe przycięcie obrazu do rozmiaru 28×28, a następnie jego przeskalowanie do 32×32.\n",
    "\n",
    "from torchvision.transforms import Compose, RandomRotation, RandomHorizontalFlip, RandomCrop, Resize\n",
    "\n",
    "train_transform = Compose([\n",
    "    ToTensor(),\n",
    "    RandomRotation(degrees=15),\n",
    "    RandomHorizontalFlip(p=0.5),\n",
    "    RandomCrop(28),\n",
    "    Resize((32, 32))\n",
    "])\n",
    "\n",
    "test_transform = ToTensor()\n",
    "\n",
    "training_data = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "test_data = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=test_transform\n",
    ")\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break\n",
    "\n",
    "for X, y in train_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
